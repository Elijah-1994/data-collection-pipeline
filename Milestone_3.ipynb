{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from uuid import uuid4\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import tempfile\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterstonesScrapper:\n",
    "    '''\n",
    "        This class represents the process of using selenium to access the manga book section on waterstones,\n",
    "        and to define methods take in hmtl elements to scrape and store text and image data from each book on the first 5 pages.\n",
    "\n",
    "        Attributes:\n",
    "            driver: initalises the webdriver.chrome method to drive to the waterstones website.\n",
    "            raw_data_dictionary: creates folder directory to store data.\n",
    "            images_directory: creates folder directory to store image data.\n",
    "            manga_images_directory : creates folder directory to store image data from the manga section.\n",
    "            parent_directory : parent directory to where project is saved.\n",
    "            time_stamps: intialises the datetime.now() method which returns the current date and time.\n",
    "            time_stamps_formated: intialises the strftime.() method which returns the date and current time in string format.\n",
    "            date: intialises the strftime.() method which returns the date in string format.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        '''\n",
    "        See help(WaterstoneScrapper) for accurate signature\n",
    "        '''\n",
    "        self.driver = webdriver.Chrome() \n",
    "        self.driver.get(\"https://www.waterstones.com/\")\n",
    "        self._raw_data_directory = 'raw_data/'\n",
    "        self._images_directory ='raw_data/images' \n",
    "        self._manga_images_directory ='raw_data/images/manga'\n",
    "        self._parent_directory = 'C:/Users/kenza/OneDrive/Desktop/GitBash/data-collection-pipeline/'\n",
    "        self.time_stamps = datetime.now()\n",
    "        self.time_stamps_formated = self.time_stamps.strftime(\"%Y-%m-%d,%H:%M:%S\")\n",
    "        self.date = self.time_stamps.strftime(\"%Y-%m-%d\")\n",
    "   \n",
    "    pass\n",
    "\n",
    "    def create_directory(self,):\n",
    "        if not os.path.exists(\"raw_data\"):\n",
    "            raw_data_directory = self.raw_data_directory\n",
    "            images_directory = self.images_directory\n",
    "            manga_images_directory = self.manga_images_directory\n",
    "            parent_directory = self.parent_directory\n",
    "            path = os.path.join(parent_directory, raw_data_directory)\n",
    "            os.mkdir(path)\n",
    "            path = os.path.join(parent_directory, images_directory)\n",
    "            os.mkdir(path)\n",
    "            path = os.path.join(parent_directory, manga_images_directory)\n",
    "            os.mkdir(path)\n",
    "    pass\n",
    "    \n",
    "    def accept_cookies(self):\n",
    "            try:\n",
    "                accept_cookies_button = self.driver.find_element(by=By.XPATH, value='//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "                accept_cookies_button.click()\n",
    "                time.sleep(1)\n",
    "            except AttributeError: \n",
    "                accept_cookies_button = self.driver.find_element(by=By.XPATH, value='//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "                accept_cookies_button.click()\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def navigate_to_manga_page_1(self):\n",
    "        manga_a_tag =  self.driver.find_elements(by=By.XPATH, value='//a[@class=\"name\"]')\n",
    "        a_tag_links = []\n",
    "        for element in manga_a_tag:\n",
    "            link = element.get_attribute('href')\n",
    "            a_tag_links.append(link)\n",
    "        html_links=[]\n",
    "        for element in a_tag_links:\n",
    "            if element =='https://www.waterstones.com/category/graphic-novels-manga/manga':\n",
    "                html_links.append(element)\n",
    "        manga_link = html_links[0]\n",
    "        self.driver.get(manga_link)\n",
    "        navigate_to_see_more_manga_page = self.driver.find_elements(by=By.XPATH, value='//a[@class=\"button button-teal\"]')\n",
    "        see_more_manga_page_list = []\n",
    "        for element in navigate_to_see_more_manga_page:\n",
    "            link = element.get_attribute('href') \n",
    "            see_more_manga_page_list.append(link)\n",
    "        manga_page = []\n",
    "        for element in see_more_manga_page_list:\n",
    "            if element == 'https://www.waterstones.com/category/graphic-novels-manga/manga?page=1':\n",
    "                manga_page.append(element)\n",
    "        manga_page_1 = manga_page[0]\n",
    "        return(manga_page_1)\n",
    "    pass\n",
    "\n",
    "    def get_website_links_manga_page_1(self,):\n",
    "        navigate_to_manga_page_1 = self.navigate_to_manga_page_1()\n",
    "        self.driver.get(navigate_to_manga_page_1)\n",
    "        current_url = self.driver.current_url\n",
    "        time.sleep(3)\n",
    "        self.driver.find_element('xpath', '//body').send_keys(Keys.END)\n",
    "        manga_page_container = self.driver.find_elements(by=By.XPATH,value='//div[@class=\"image-wrap\"]/a')\n",
    "        list_of_hmtl_links = []\n",
    "        for element in manga_page_container:\n",
    "            link = element.get_attribute('href')\n",
    "            list_of_hmtl_links.append(link)\n",
    "        self.driver.get(link)\n",
    "        return (list_of_hmtl_links,current_url)\n",
    "    pass\n",
    "    \n",
    "    def get_website_links_manga_page_2_to_page_5(self,):\n",
    "        list_of_hmtl_links,current_url = self.get_website_links_manga_page_1()\n",
    "        current_url = current_url[0:63]\n",
    "        current_url = current_url + \"/page/\"\n",
    "        list_of_manga_page_links = []\n",
    "        for element in range (2,3):\n",
    "            list_of_manga_page_links.append(f'{current_url}{element}')\n",
    "            self.driver.get(current_url)\n",
    "        for element in list_of_manga_page_links:\n",
    "            self.driver.get(element)\n",
    "            time.sleep(3)\n",
    "            self.driver.find_element('xpath', '//body').send_keys(Keys.END)\n",
    "            manga_container = self.driver.find_elements(by=By.XPATH,value='//div[@class=\"image-wrap\"]/a')\n",
    "            for element in manga_container:\n",
    "                link = element.get_attribute('href')\n",
    "                list_of_hmtl_links.append(link)\n",
    "        print (list_of_hmtl_links)\n",
    "        return (list_of_hmtl_links)\n",
    "    pass\n",
    "    \n",
    "    def scrape_links_and_store_text_image_data(self,):\n",
    "        combined_list_of_html_links = self.get_website_links_manga_page_2_to_page_5()\n",
    "        big_list_of_data_dictionaries=[]\n",
    "        for element in combined_list_of_html_links:\n",
    "            dict_properties = {'IDS':[], 'Timestamps':[],'ISBNS':[],'Names': [], 'Authors': [], 'Publishers': [], 'Book_Formats':[], 'Descriptions': [],}\n",
    "            self.driver.get(element)\n",
    "            image_ids = str(uuid4())\n",
    "            time.sleep(10)\n",
    "            dict_properties['IDS'].append(image_ids)\n",
    "            timestamps = self.time_stamps_formated\n",
    "            dict_properties['Timestamps'].append(timestamps)\n",
    "            isbn =self.driver.find_element(by=By.XPATH, value='//span[contains(@itemprop,\"isbn\")]').get_attribute(\"textContent\")\n",
    "            dict_properties['ISBNS'].append(isbn)\n",
    "            name = self.driver.find_element(by=By.XPATH, value='//span[@class=\"book-title\"]').text\n",
    "            dict_properties['Names'].append(name)\n",
    "            author = self.driver.find_element(by=By.XPATH, value= '//span[contains(@itemprop,\"author\")]').text\n",
    "            dict_properties['Authors'].append(author)\n",
    "            publisher = self.driver.find_element(by=By.XPATH, value='//span[contains(@itemprop,\"publisher\")]').get_attribute(\"textContent\")\n",
    "            dict_properties['Publishers'].append(publisher)\n",
    "            book_format =  self.driver.find_element(by=By.XPATH, value='//span[@class=\"name\"]').text\n",
    "            dict_properties['Book_Formats'].append(book_format)\n",
    "            description= self.driver.find_element(by=By.XPATH, value='//div[@class=\"tabs-content-container clearfix\"]//div[@itemprop=\"description\"]').text\n",
    "            dict_properties['Descriptions'].append(description)\n",
    "            image = self.driver.find_element(by=By.XPATH, value='//div[@class=\"book-image-main\"]/img')\n",
    "            img = image.get_attribute('src')\n",
    "            img_content = requests.get(img).content\n",
    "            name = 'raw_data/images/manga/' +f'{self.date}_' + f'{image_ids}' + '.jpg'\n",
    "            with open (name,'wb') as handler:\n",
    "                handler.write(img_content)\n",
    "            big_list_of_data_dictionaries.append(dict_properties)\n",
    "        self.driver.quit()\n",
    "        return big_list_of_data_dictionaries\n",
    "    pass\n",
    "\n",
    "    def save_raw_dictionaries(self,big_list_of_data_dictionaries):\n",
    "        with open(\"raw_data/data.json\", mode=\"w\", encoding= \"utf-8\") as file:\n",
    "            file.write(json.dumps((big_list_of_data_dictionaries), default=str))   \n",
    "    pass\n",
    "\n",
    "def scrapper_method():\n",
    "    scrapper = WaterstonesScrapper()\n",
    "    scrapper.create_directory()\n",
    "    scrapper.accept_cookies()\n",
    "    scrapper.navigate_to_manga_page_1()\n",
    "    scrapper.get_website_links_manga_page_1()\n",
    "    scrapper.get_website_links_manga_page_2_to_page_5()\n",
    "    scrape = scrapper.save_raw_dictionaries(scrapper.scrape_links_and_store_text_image_data())\n",
    "\n",
    "pass\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scrapper_method()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38f9fe4226d84d9e13099a048607a3090ac78dd253a8865dfaa4f1df58d270e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
